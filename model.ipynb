{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe6bfce3-2820-475f-a7b9-247fe83fac22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73ddf2c0-54b1-4804-a2ef-6ddd3d83ec7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48150918-165f-4b8f-96b8-a7a130614b77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 8192)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torchvision.transforms import Compose\n",
    "from Utilities.transforms import minmax\n",
    "from Utilities.dataloader import EEGDataLoader\n",
    "\n",
    "transforms = Compose([\n",
    "    minmax,\n",
    "])\n",
    "\n",
    "dl = EEGDataLoader(\"./dataset\", transforms)\n",
    "\n",
    "signal, label = dl.__getitem__(12)\n",
    "print(np.array(signal).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f252f49d-703a-41b4-ad6b-b3299d460183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EEGModel(nn.Module):\n",
    "    channels = 16\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(EEGModel, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv1d(self.channels, 32, 11),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(3),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout2d(p=0.6),\n",
    "            \n",
    "            nn.Conv1d(32, 64, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout2d(p=0.6),\n",
    "            \n",
    "            nn.Conv1d(64, 128, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool1d(3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout2d(p=0.6),\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(301, 128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Dropout2d(p=0.6),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(2560, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        x = torch.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        print(x.shape)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "faf29611-9d8b-4f1c-bc62-14337cd0c1e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EEGModel(\n",
       "  (features): Sequential(\n",
       "    (0): Conv1d(16, 32, kernel_size=(11,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): AvgPool1d(kernel_size=(3,), stride=(3,), padding=(0,))\n",
       "    (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): Dropout2d(p=0.6, inplace=False)\n",
       "    (5): Conv1d(32, 64, kernel_size=(5,), stride=(1,))\n",
       "    (6): ReLU()\n",
       "    (7): AvgPool1d(kernel_size=(3,), stride=(3,), padding=(0,))\n",
       "    (8): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): Dropout2d(p=0.6, inplace=False)\n",
       "    (10): Conv1d(64, 128, kernel_size=(3,), stride=(1,))\n",
       "    (11): ReLU()\n",
       "    (12): AvgPool1d(kernel_size=(3,), stride=(3,), padding=(0,))\n",
       "    (13): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Dropout2d(p=0.6, inplace=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=301, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (3): Dropout2d(p=0.6, inplace=False)\n",
       "    (4): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=2560, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = EEGModel()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "41cb9cd9-9fe0-4881-9d15-0f87c8b28faf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [-1, 32, 8182]           5,664\n",
      "              ReLU-2             [-1, 32, 8182]               0\n",
      "         AvgPool1d-3             [-1, 32, 2727]               0\n",
      "       BatchNorm1d-4             [-1, 32, 2727]              64\n",
      "         Dropout2d-5             [-1, 32, 2727]               0\n",
      "            Conv1d-6             [-1, 64, 2723]          10,304\n",
      "              ReLU-7             [-1, 64, 2723]               0\n",
      "         AvgPool1d-8              [-1, 64, 907]               0\n",
      "       BatchNorm1d-9              [-1, 64, 907]             128\n",
      "        Dropout2d-10              [-1, 64, 907]               0\n",
      "           Conv1d-11             [-1, 128, 905]          24,704\n",
      "             ReLU-12             [-1, 128, 905]               0\n",
      "        AvgPool1d-13             [-1, 128, 301]               0\n",
      "      BatchNorm1d-14             [-1, 128, 301]             256\n",
      "        Dropout2d-15             [-1, 128, 301]               0\n",
      "           Linear-16             [-1, 128, 128]          38,656\n",
      "           Linear-17              [-1, 128, 64]           8,256\n",
      "           Linear-18              [-1, 128, 32]           2,080\n",
      "        Dropout2d-19              [-1, 128, 32]               0\n",
      "           Linear-20              [-1, 128, 10]             330\n",
      "           Linear-21                       [-1]          25,610\n",
      "================================================================\n",
      "Total params: 116,052\n",
      "Trainable params: 116,052\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.50\n",
      "Forward/backward pass size (MB): 12.89\n",
      "Params size (MB): 0.44\n",
      "Estimated Total Size (MB): 13.83\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kacper/Documents/venv/lib/python3.10/site-packages/torch/nn/functional.py:1338: UserWarning: dropout2d: Received a 3D input to dropout2d and assuming that channel-wise 1D dropout behavior is desired - input is interpreted as shape (N, C, L), where C is the channel dim. This behavior will change in a future release to interpret the input as one without a batch dimension, i.e. shape (C, H, W). To maintain the 1D channel-wise dropout behavior, please switch to using dropout1d instead.\n",
      "  warnings.warn(\"dropout2d: Received a 3D input to dropout2d and assuming that channel-wise \"\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(model, (16, 8192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb32c288-39db-46c4-b064-2a560ec4cf9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
